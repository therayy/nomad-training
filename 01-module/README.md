script

So when we talk about nomad, one of the things we see which is really common is this deployment pattern of a single operating system with a single application running on top of that and in this configuration they meet on a top of a single VM.

Now the challenge that we often see with this configuration is you really have two distinct audience here, you have your developer DEV, and the Operation DEV. As the Developer cares about the application lifecycle, so they care about scaling up scaling down changing configuration deploying their new version. But the same time you have you operator audiance and they care about a different set of things, they care about are we running the right version of the OS is it patch do we have enough capacity in our fleet and the challenge is although have a different set of concerns they have to coordinate because the application is running on an OS on a VM at the end of the day.

So what we often see is the development group has to file a ticket, so anytime the development group wants to do anything application lifecycle related there to file a ticket aganist the opertations group and that's the layer at which the coordination is done. (DEVOPS)

The first thing we are looking at when we talk about Nomad, how do we split this so we can have independent workflows, the primary goal of nomad is to sit in between here and disintermiediate and really provide a layer where we have a southbound API focused on the operator and northbound API focused on the developer.

So what does this really mean, from the Developer what we want to do is let them write their job and that;s what Nomad calls it as a job file, which is an infrastucture as code way of declaring everything about their job. So they would say I have this web application I want to run its version 10 of my application and I want three instances of it. And now the developer just submits this job file to Nomads API. Its Nomads responsibility to find space in this cluster to run the job which is 3 instances of this web server, so we might have a hundred node cluster that we are running and know that's going to find 3 machines that have available capacity and deploy the web server there.

Now as a developer when we come back and say you know what I want to deploy version 11 of my application and also specify what deployment strategy I want do I wanna use a canary or blue/green deployment or just a rolling deployment, you will simply change your job file to reflect the new version and resubmit it to Nomads API. And Nomad takes care of these changes across the fleet safely, in addition to just managing deploying our application as well as making changes to it right as we change version or scale up and down so we could easily visit the job file and change our 3 instances and apply the change lets say to 5 and Nomad will go run 2 more copies of this. The other thing it really does is how we automate some of the operational challenges that are historically part of the operationals group. 

So we talk about these sort of operational issues, it's things like how do we make sure if this application crashes that it gets restarted? so we want to make sure that we can greacefully restart the application and ensure it stays online even though it might crashed or experienced an issue. The other side of those what if the machine that we are running on or the rack or the cage or the data center we are running on fails. Well we really want to do is automatically reschedule the application onto a different machine that has capacity. So if Nomad detects that the machine is down, it will automatically find another machine in the cluster to reschedule the application onto, so these are traditionally things where we might have paged someone to go deal with operational issue and provide a reliable service but instead Nomad can handle these situations automatically.

